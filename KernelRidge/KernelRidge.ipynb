{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=  'C:/Users/felipe/Documents/Brain/'\n",
    "#import sys\n",
    "#sys.path.append(path) \n",
    "path_=  'C:/Users/felipe/Documents/Brain/Brain_Model/'\n",
    "import sys\n",
    "sys.path.append(path_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\felipe\\Documents\\Brain\\brain_age_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from base_regressor import BaseRegressor\n",
    "from Plotter import Plotter\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "class KernelRidgeRegressor(BaseRegressor):\n",
    "    def __init__(self, save_path=None, scaler=None, params=None, params_space=None, fit_params_search=None, model_params_search=None, fit_params_train=None, model_params_train=None, name_model=\"KernelRidge\"):\n",
    "        super().__init__(save_path, scaler, params, params_space, fit_params_search, model_params_search, fit_params_train, model_params_train, name_model)\n",
    "\n",
    "        self.model_ml = KernelRidge\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'alpha': 1.0,\n",
    "                'kernel': 'linear',\n",
    "                'gamma': None\n",
    "            }\n",
    "        if params_space is None:\n",
    "            self.params_space = {\n",
    "                'alpha': Real(1e-3, 10.0, prior='log-uniform'),\n",
    "                'kernel': Categorical(['linear', 'rbf', 'poly', 'sigmoid']),\n",
    "                'gamma': Real(1e-5, 1e-1, prior='log-uniform')\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 72 Features\n",
    "features = ['Alpha2_canon_EPP_HPC_left', 'Alpha2_canon_EPP_HPC_right', 'Alpha2_canon_EPP_PARIET_left', 'Alpha2_canon_EPP_PARIET_right', 'Alpha2_canon_EPP_OCC_left', 'Alpha2_canon_EPP_OCC_right', 'Alpha2_canon_RPD_HPC_left', 'Alpha2_canon_RPD_HPC_right', 'Alpha2_canon_RPD_CING_left', 'Alpha2_canon_RPD_CING_right', 'Alpha2_canon_RPD_PARIET_left', 'Alpha2_canon_RPD_PARIET_right', 'Alpha2_canon_RPD_OCC_left', 'Alpha2_canon_RPD_OCC_right', 'High_subj_spec_EPP_HPC_left', 'High_subj_spec_EPP_HPC_right', 'High_subj_spec_EPP_CING_left', 'High_subj_spec_EPP_CING_right', 'High_subj_spec_EPP_PARIET_left', 'High_subj_spec_EPP_PARIET_right', 'High_subj_spec_EPP_OCC_left', 'High_subj_spec_EPP_OCC_right', 'High_subj_spec_RPD_HPC_left', 'High_subj_spec_RPD_HPC_right', 'High_subj_spec_RPD_CING_left', 'High_subj_spec_RPD_CING_right', 'High_subj_spec_RPD_PARIET_left', 'High_subj_spec_RPD_PARIET_right', 'High_subj_spec_RPD_OCC_left', 'High_subj_spec_RPD_OCC_right', 'Low_subj_spec_EPP_HPC_left', 'Low_subj_spec_EPP_HPC_right', 'Low_subj_spec_EPP_CING_left', 'Low_subj_spec_EPP_CING_right', 'Low_subj_spec_EPP_PARIET_left', 'Low_subj_spec_EPP_PARIET_right', 'Low_subj_spec_EPP_OCC_left', 'Low_subj_spec_EPP_OCC_right', 'Low_subj_spec_RPD_HPC_left', 'Low_subj_spec_RPD_HPC_right', 'Low_subj_spec_RPD_CING_left', 'Low_subj_spec_RPD_CING_right', 'Low_subj_spec_RPD_PARIET_left', 'Low_subj_spec_RPD_PARIET_right', 'Low_subj_spec_RPD_OCC_left', 'Low_subj_spec_RPD_OCC_right', 'TF_ORB_left', 'TF_ORB_right', 'TF_IFG_left', 'TF_IFG_right', 'TF_MFG_left', 'TF_MFG_right', 'TF_SFG_left', 'TF_SFG_right', 'TF_HPC_left', 'TF_HPC_right', 'TF_INS_left', 'TF_INS_right', 'IAF_ORB_left', 'IAF_ORB_right', 'IAF_IFG_left', 'IAF_IFG_right', 'IAF_MFG_left', 'IAF_MFG_right', 'IAF_SFG_left', 'IAF_SFG_right', 'IAF_HPC_left', 'IAF_HPC_right', 'IAF_INS_left', 'IAF_INS_right', 'IAF_OCC_left', 'IAF_OCC_right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_path_CN = f'{path}Brain_Age/CN_freq.xlsx'\n",
    "\n",
    "df_CN = pd.read_excel(file_path_CN)\n",
    "\n",
    "\n",
    "df_CN_filtrado = df_CN[(df_CN['Age'] >=20) & (df_CN['Age'] <= 90)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_CN = df_CN_filtrado[features]\n",
    "y_CN = df_CN_filtrado[\"Age\"]\n",
    "ID_CN = df_CN_filtrado[\"ID-unique\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_CN)\n",
    "\n",
    "X_CN_scaled = scaler.transform(X_CN)\n",
    "\n",
    "X_CN_scaled = pd.DataFrame(X_CN_scaled, columns=X_CN.columns)\n",
    "\n",
    "df_concatenado_CN = pd.concat([X_CN, y_CN, ID_CN], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelRidgeRegressor()\n",
    "Plotters = Plotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "#'neg_mean_absolute_error'\n",
    "#'neg_mean_squared_error'\n",
    "#'neg_root_mean_squared_error'\n",
    "#'explained_variance'\n",
    "#'r2'\n",
    "\n",
    "opt_model, best_params = model.search_best_model (X=X_CN_scaled, y=y_CN, n_iter_=50, scoring_metric='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}Brain_Age/Opt_Model/opt_KernelRidge.pickle', 'wb') as file:\n",
    "        pickle.dump(opt_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}Brain_Age/Opt_Model/opt_KernelRidge.pickle', 'rb') as file:\n",
    "    opt_model= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = opt_model.cv_results_['mean_test_score'][:50]\n",
    "Plotters.plot_iteration(y=score, title='BayesSearch', xlabel='Iteration', ylabel='score', legend_result=False, best_result=True, y_size=2, font='Times New Roman', weight='normal', mode=2, band_width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ = model.best_hyper(num_best=10, opt_model=opt_model, num_max=50)\n",
    "best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Dividir el dataframe\n",
    "df_train, df_test = train_test_split(df_concatenado_CN, test_size=0.2, random_state=42)\n",
    "\n",
    "# Resultado: df_train y df_test son dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_CN_train,results_labels_df_CN_val, results_labels_list, results_model, results_per_fold_CN_train,results_per_fold_CN_val, results_per_fold_pat= model.trainer(df_concatenado_CN=df_train, n_splits=10, n_iterations=1, params_=best_params_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_CN_test = df_test.iloc[:, :-2]  # Features\n",
    "y_CN_test = df_test.iloc[:, -2]   # Labels (Age)\n",
    "ID_CN_test = df_test.iloc[:, -1]\n",
    "\n",
    "results_labels_df_CN_test = pd.DataFrame(columns=['y_labels', 'y_pred', 'y_pred_corrected', 'GAP', 'GAP_corrected', 'ID-unique'])\n",
    "results_per_fold_CN_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(10):\n",
    "    slope=results_model['slope'][fold]\n",
    "    intercept=results_model['intercept'][fold]\n",
    "    mean_X_train_kf=results_model['mean_X_train_kf'][fold]\n",
    "    std_X_train_kf=results_model['std_X_train_kf'][fold]\n",
    "\n",
    "    X_test_CN_scaled = (X_CN_test - mean_X_train_kf) / std_X_train_kf\n",
    "\n",
    "    model_ = results_model['model'][fold]\n",
    "\n",
    "\n",
    "    y_pred_CN_test = model_.predict(X_test_CN_scaled)\n",
    "    gap_CN_test = y_pred_CN_test - y_CN_test\n",
    "\n",
    "\n",
    "    y_pred_corrected_CN_test = y_pred_CN_test - (slope * y_CN_test + intercept)\n",
    "    corrected_gap_CN_test = gap_CN_test - (slope * y_CN_test + intercept)\n",
    "\n",
    "\n",
    "    temp_CN_df_test = pd.DataFrame({\n",
    "                        'y_labels': y_CN_test,\n",
    "                        'y_pred': y_pred_CN_test,\n",
    "                        'y_pred_corrected': y_pred_corrected_CN_test,\n",
    "                        'GAP': gap_CN_test,\n",
    "                        'GAP_corrected': corrected_gap_CN_test,\n",
    "                        'ID-unique': ID_CN_test\n",
    "                    })\n",
    "\n",
    "    results_labels_df_CN_test = pd.concat([results_labels_df_CN_test, temp_CN_df_test], ignore_index=True)\n",
    "    results_per_fold_CN_test.append(temp_CN_df_test.copy())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Lista de métricas\n",
    "#metrics = ['mae', 'mse', 'rmse', 'r2']\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "#results = {'train': {m: [] for m in metrics}, \n",
    "#           #'val': {m: [] for m in metrics}, \n",
    "#           'test': {m: [] for m in metrics}}\n",
    "\n",
    "metrics = ['mae', 'mse', 'rmse', 'r2']\n",
    "results = {'train': {m: [] for m in metrics}, \n",
    "        'val': {m: [] for m in metrics}, \n",
    "        'test': {m: [] for m in metrics}}\n",
    "\n",
    "# Función para calcular las métricas\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2}\n",
    "\n",
    "# Recorrer los 10 folds\n",
    "for fold_idx in range(10):\n",
    "    fold_data_CN_train = results_per_fold_CN_train[0][fold_idx]\n",
    "    fold_data_CN_val = results_per_fold_CN_val[0][fold_idx]\n",
    "    fold_data_CN_test = results_per_fold_CN_test[fold_idx]\n",
    "\n",
    "    # Obtener los valores de y_labels e y_pred_corrected\n",
    "    y_true_1 = fold_data_CN_train['y_labels']\n",
    "    y_pred_1 = fold_data_CN_train['y_pred']\n",
    "    y_true_2 = fold_data_CN_val['y_labels']\n",
    "    y_pred_2 = fold_data_CN_val['y_pred']\n",
    "    y_true_3 = fold_data_CN_test['y_labels']\n",
    "    y_pred_3 = fold_data_CN_test['y_pred']\n",
    "    \n",
    "    # Calcular métricas para el fold actual\n",
    "    fold_metrics_1 = calculate_metrics(y_true_1, y_pred_1)\n",
    "    fold_metrics_2 = calculate_metrics(y_true_2, y_pred_2)\n",
    "    fold_metrics_3 = calculate_metrics(y_true_3, y_pred_3)\n",
    "\n",
    "    # Guardar los resultados en el diccionario\n",
    "    for metric in metrics:\n",
    "        results['train'][metric].append(fold_metrics_1[metric])\n",
    "        results['val'][metric].append(fold_metrics_2[metric]) \n",
    "        results['test'][metric].append(fold_metrics_3[metric]) \n",
    "\n",
    "# Imprimir resultados\n",
    "#for metric in metrics:\n",
    "#    print(f\"{metric}: {results['train'][metric]}\")\n",
    "\n",
    "labels = ['train', 'val','test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_metricas_evaluacion(results, labels=labels, name_set='Cross Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = results['val']['mae']\n",
    "min_mae_index = mae_list.index(min(mae_list))\n",
    "\n",
    "y_labels_=results_per_fold_CN_test[min_mae_index]['y_labels']\n",
    "y_pred_= results_per_fold_CN_test[min_mae_index]['y_pred_corrected']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_regresion(y=y_pred_,x= y_labels_, label_='Test Data',x_ticks_step=25,y_ticks_step=25,x_min_limit=0,y_min_limit=0,x_max_limit=100,y_max_limit=100,color='Black', title='KernelRidge',line_ideal=False,confidence_interval=True,  alpha=0.7,xlabel='Chronological Age',ylabel='Brain Age',color_confidence_interval='blue',alpha_confidence_interval=0.4,color_line_fit='red', details=True, font='Times New Roman', weight='normal', x_size=3,y_size=3, legend=False, fontsize=13, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_regresion(y=y_pred_,x= y_labels_, label_='Test Data',x_ticks_step=25,y_ticks_step=25,x_min_limit=0,y_min_limit=0,x_max_limit=100,y_max_limit=100,color='Ivory', title='KernelRidge',line_ideal=False,confidence_interval=True,  alpha=0.5,xlabel='Chronological Age',ylabel='Brain Age',color_confidence_interval='gray',alpha_confidence_interval=0.7,color_line_fit=(0, 0, 0), details=False, font='Times New Roman', weight='normal', x_size=2,y_size=2.5, legend=False, fontsize=13, mode=3, legend_metrics=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_age_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
