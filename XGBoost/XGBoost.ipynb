{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/felip/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/'\n",
    "path_=  'C:/Users/felip/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/Brain_Model/'\n",
    "import sys\n",
    "sys.path.append(path_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from base_regressor import BaseRegressor\n",
    "from Plotter import Plotter\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "class XGBoostRegressor(BaseRegressor):\n",
    "    def __init__(self, save_path=None, scaler=None, params=None, params_space=None, fit_params_search=None,model_params_search=None,fit_params_train=None,model_params_train=None, name_model=\"XGBoost\"):\n",
    "        super().__init__(save_path, scaler, params, params_space, fit_params_search ,model_params_search,fit_params_train ,model_params_train, name_model)\n",
    "        \n",
    "        self.model_ml = xgb.XGBRegressor\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'n_estimators': 100,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': 3,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8\n",
    "            }\n",
    "        if params_space is None:\n",
    "            self.params_space = {\n",
    "                'n_estimators': Integer(50, 5000),\n",
    "                'learning_rate': Real(0.0001, 0.2, prior='log-uniform'),\n",
    "                'max_depth': Integer(3, 10),\n",
    "                'subsample': Real(0.1, 1.0),\n",
    "                'colsample_bytree': Real(0.1, 1.0)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 72 Features\n",
    "features = ['Alpha2_canon_EPP_HPC_left', 'Alpha2_canon_EPP_HPC_right', 'Alpha2_canon_EPP_PARIET_left', 'Alpha2_canon_EPP_PARIET_right', 'Alpha2_canon_EPP_OCC_left', 'Alpha2_canon_EPP_OCC_right', 'Alpha2_canon_RPD_HPC_left', 'Alpha2_canon_RPD_HPC_right', 'Alpha2_canon_RPD_CING_left', 'Alpha2_canon_RPD_CING_right', 'Alpha2_canon_RPD_PARIET_left', 'Alpha2_canon_RPD_PARIET_right', 'Alpha2_canon_RPD_OCC_left', 'Alpha2_canon_RPD_OCC_right', 'High_subj_spec_EPP_HPC_left', 'High_subj_spec_EPP_HPC_right', 'High_subj_spec_EPP_CING_left', 'High_subj_spec_EPP_CING_right', 'High_subj_spec_EPP_PARIET_left', 'High_subj_spec_EPP_PARIET_right', 'High_subj_spec_EPP_OCC_left', 'High_subj_spec_EPP_OCC_right', 'High_subj_spec_RPD_HPC_left', 'High_subj_spec_RPD_HPC_right', 'High_subj_spec_RPD_CING_left', 'High_subj_spec_RPD_CING_right', 'High_subj_spec_RPD_PARIET_left', 'High_subj_spec_RPD_PARIET_right', 'High_subj_spec_RPD_OCC_left', 'High_subj_spec_RPD_OCC_right', 'Low_subj_spec_EPP_HPC_left', 'Low_subj_spec_EPP_HPC_right', 'Low_subj_spec_EPP_CING_left', 'Low_subj_spec_EPP_CING_right', 'Low_subj_spec_EPP_PARIET_left', 'Low_subj_spec_EPP_PARIET_right', 'Low_subj_spec_EPP_OCC_left', 'Low_subj_spec_EPP_OCC_right', 'Low_subj_spec_RPD_HPC_left', 'Low_subj_spec_RPD_HPC_right', 'Low_subj_spec_RPD_CING_left', 'Low_subj_spec_RPD_CING_right', 'Low_subj_spec_RPD_PARIET_left', 'Low_subj_spec_RPD_PARIET_right', 'Low_subj_spec_RPD_OCC_left', 'Low_subj_spec_RPD_OCC_right', 'TF_ORB_left', 'TF_ORB_right', 'TF_IFG_left', 'TF_IFG_right', 'TF_MFG_left', 'TF_MFG_right', 'TF_SFG_left', 'TF_SFG_right', 'TF_HPC_left', 'TF_HPC_right', 'TF_INS_left', 'TF_INS_right', 'IAF_ORB_left', 'IAF_ORB_right', 'IAF_IFG_left', 'IAF_IFG_right', 'IAF_MFG_left', 'IAF_MFG_right', 'IAF_SFG_left', 'IAF_SFG_right', 'IAF_HPC_left', 'IAF_HPC_right', 'IAF_INS_left', 'IAF_INS_right', 'IAF_OCC_left', 'IAF_OCC_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_path_CN = f'{path}Brain_Age/CN_freq.xlsx'\n",
    "\n",
    "df_CN = pd.read_excel(file_path_CN)\n",
    "\n",
    "\n",
    "df_CN_filtrado = df_CN[(df_CN['Age'] >=20) & (df_CN['Age'] <= 90)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_CN = df_CN_filtrado[features]\n",
    "y_CN = df_CN_filtrado[\"Age\"]\n",
    "ID_CN = df_CN_filtrado[\"ID-unique\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_CN)\n",
    "\n",
    "X_CN_scaled = scaler.transform(X_CN)\n",
    "\n",
    "X_CN_scaled = pd.DataFrame(X_CN_scaled, columns=X_CN.columns)\n",
    "\n",
    "df_concatenado_CN = pd.concat([X_CN, y_CN, ID_CN], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBoostRegressor()\n",
    "Plotters = Plotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "#'neg_mean_absolute_error'\n",
    "#'neg_mean_squared_error'\n",
    "#'neg_root_mean_squared_error'\n",
    "#'explained_variance'\n",
    "#'r2'\n",
    "\n",
    "opt_model, best_params = model.search_best_model (X=X_CN_scaled, y=y_CN, n_iter_=50, scoring_metric='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}Brain_Age/Opt_Model/opt_XGBoost.pickle', 'wb') as file:\n",
    "        pickle.dump(opt_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_age_env (C:\\python_env\\brain_age_env)",
   "language": "python",
   "name": "brain_age_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
