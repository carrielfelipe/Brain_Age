{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/felip/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/'\n",
    "path_=  'C:/Users/felip/OneDrive - Universidad Técnica Federico Santa María/Documentos/Brain/Brain_Model/'\n",
    "import sys\n",
    "sys.path.append(path_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from base_regressor import BaseRegressor\n",
    "from Plotter import Plotter\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "class XGBoostRegressor(BaseRegressor):\n",
    "    def __init__(self, save_path=None, scaler=None, params=None, params_space=None, fit_params_search=None,model_params_search=None,fit_params_train=None,model_params_train=None, name_model=\"XGBoost\"):\n",
    "        super().__init__(save_path, scaler, params, params_space, fit_params_search ,model_params_search,fit_params_train ,model_params_train, name_model)\n",
    "        \n",
    "        self.model_ml = xgb.XGBRegressor\n",
    "        if params is None:\n",
    "            self.params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'n_estimators': 100,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': 3,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8\n",
    "            }\n",
    "        if params_space is None:\n",
    "            self.params_space = {\n",
    "                'n_estimators': Integer(50, 5000),\n",
    "                'learning_rate': Real(0.0001, 0.2, prior='log-uniform'),\n",
    "                'max_depth': Integer(3, 10),\n",
    "                'subsample': Real(0.1, 1.0),\n",
    "                'colsample_bytree': Real(0.1, 1.0)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 72 Features\n",
    "features = ['Alpha2_canon_EPP_HPC_left', 'Alpha2_canon_EPP_HPC_right', 'Alpha2_canon_EPP_PARIET_left', 'Alpha2_canon_EPP_PARIET_right', 'Alpha2_canon_EPP_OCC_left', 'Alpha2_canon_EPP_OCC_right', 'Alpha2_canon_RPD_HPC_left', 'Alpha2_canon_RPD_HPC_right', 'Alpha2_canon_RPD_CING_left', 'Alpha2_canon_RPD_CING_right', 'Alpha2_canon_RPD_PARIET_left', 'Alpha2_canon_RPD_PARIET_right', 'Alpha2_canon_RPD_OCC_left', 'Alpha2_canon_RPD_OCC_right', 'High_subj_spec_EPP_HPC_left', 'High_subj_spec_EPP_HPC_right', 'High_subj_spec_EPP_CING_left', 'High_subj_spec_EPP_CING_right', 'High_subj_spec_EPP_PARIET_left', 'High_subj_spec_EPP_PARIET_right', 'High_subj_spec_EPP_OCC_left', 'High_subj_spec_EPP_OCC_right', 'High_subj_spec_RPD_HPC_left', 'High_subj_spec_RPD_HPC_right', 'High_subj_spec_RPD_CING_left', 'High_subj_spec_RPD_CING_right', 'High_subj_spec_RPD_PARIET_left', 'High_subj_spec_RPD_PARIET_right', 'High_subj_spec_RPD_OCC_left', 'High_subj_spec_RPD_OCC_right', 'Low_subj_spec_EPP_HPC_left', 'Low_subj_spec_EPP_HPC_right', 'Low_subj_spec_EPP_CING_left', 'Low_subj_spec_EPP_CING_right', 'Low_subj_spec_EPP_PARIET_left', 'Low_subj_spec_EPP_PARIET_right', 'Low_subj_spec_EPP_OCC_left', 'Low_subj_spec_EPP_OCC_right', 'Low_subj_spec_RPD_HPC_left', 'Low_subj_spec_RPD_HPC_right', 'Low_subj_spec_RPD_CING_left', 'Low_subj_spec_RPD_CING_right', 'Low_subj_spec_RPD_PARIET_left', 'Low_subj_spec_RPD_PARIET_right', 'Low_subj_spec_RPD_OCC_left', 'Low_subj_spec_RPD_OCC_right', 'TF_ORB_left', 'TF_ORB_right', 'TF_IFG_left', 'TF_IFG_right', 'TF_MFG_left', 'TF_MFG_right', 'TF_SFG_left', 'TF_SFG_right', 'TF_HPC_left', 'TF_HPC_right', 'TF_INS_left', 'TF_INS_right', 'IAF_ORB_left', 'IAF_ORB_right', 'IAF_IFG_left', 'IAF_IFG_right', 'IAF_MFG_left', 'IAF_MFG_right', 'IAF_SFG_left', 'IAF_SFG_right', 'IAF_HPC_left', 'IAF_HPC_right', 'IAF_INS_left', 'IAF_INS_right', 'IAF_OCC_left', 'IAF_OCC_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_path_CN = f'{path}Brain_Age/CN_freq.xlsx'\n",
    "\n",
    "df_CN = pd.read_excel(file_path_CN)\n",
    "\n",
    "\n",
    "df_CN_filtrado = df_CN[(df_CN['Age'] >=20) & (df_CN['Age'] <= 90)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_CN = df_CN_filtrado[features]\n",
    "y_CN = df_CN_filtrado[\"Age\"]\n",
    "ID_CN = df_CN_filtrado[\"ID-unique\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_CN)\n",
    "\n",
    "X_CN_scaled = scaler.transform(X_CN)\n",
    "\n",
    "X_CN_scaled = pd.DataFrame(X_CN_scaled, columns=X_CN.columns)\n",
    "\n",
    "df_concatenado_CN = pd.concat([X_CN, y_CN, ID_CN], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBoostRegressor()\n",
    "Plotters = Plotter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "#'neg_mean_absolute_error'\n",
    "#'neg_mean_squared_error'\n",
    "#'neg_root_mean_squared_error'\n",
    "#'explained_variance'\n",
    "#'r2'\n",
    "\n",
    "opt_model, best_params = model.search_best_model (X=X_CN_scaled, y=y_CN, n_iter_=50, scoring_metric='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}Brain_Age/Opt_Model/opt_XGBoost.pickle', 'wb') as file:\n",
    "        pickle.dump(opt_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}Brain_Age/Opt_Model/opt_Lasso.pickle', 'rb') as file:\n",
    "    opt_model= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = opt_model.cv_results_['mean_test_score'][:50]\n",
    "Plotters.plot_iteration(y=score, title='BayesSearch', xlabel='Iteration', ylabel='score', legend_result=False, best_result=True, y_size=2, font='Times New Roman', weight='normal', mode=2, band_width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ = model.best_hyper(num_best=10, opt_model=opt_model, num_max=50)\n",
    "best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Dividir el dataframe\n",
    "df_train, df_test = train_test_split(df_concatenado_CN, test_size=0.2, random_state=42)\n",
    "\n",
    "# Resultado: df_train y df_test son dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_CN_train,results_labels_df_CN_val, results_labels_list, results_model, results_per_fold_CN_train,results_per_fold_CN_val, results_per_fold_pat= model.trainer(df_concatenado_CN=df_train, n_splits=10, n_iterations=1, params_=best_params_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_CN_test = df_test.iloc[:, :-2]  # Features\n",
    "y_CN_test = df_test.iloc[:, -2]   # Labels (Age)\n",
    "ID_CN_test = df_test.iloc[:, -1]\n",
    "\n",
    "results_labels_df_CN_test = pd.DataFrame(columns=['y_labels', 'y_pred', 'y_pred_corrected', 'GAP', 'GAP_corrected', 'ID-unique'])\n",
    "results_per_fold_CN_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(10):\n",
    "    slope=results_model['slope'][fold]\n",
    "    intercept=results_model['intercept'][fold]\n",
    "    mean_X_train_kf=results_model['mean_X_train_kf'][fold]\n",
    "    std_X_train_kf=results_model['std_X_train_kf'][fold]\n",
    "\n",
    "    X_test_CN_scaled = (X_CN_test - mean_X_train_kf) / std_X_train_kf\n",
    "\n",
    "    model_ = results_model['model'][fold]\n",
    "\n",
    "\n",
    "    y_pred_CN_test = model_.predict(X_test_CN_scaled)\n",
    "    gap_CN_test = y_pred_CN_test - y_CN_test\n",
    "\n",
    "\n",
    "    y_pred_corrected_CN_test = y_pred_CN_test - (slope * y_CN_test + intercept)\n",
    "    corrected_gap_CN_test = gap_CN_test - (slope * y_CN_test + intercept)\n",
    "\n",
    "\n",
    "    temp_CN_df_test = pd.DataFrame({\n",
    "                        'y_labels': y_CN_test,\n",
    "                        'y_pred': y_pred_CN_test,\n",
    "                        'y_pred_corrected': y_pred_corrected_CN_test,\n",
    "                        'GAP': gap_CN_test,\n",
    "                        'GAP_corrected': corrected_gap_CN_test,\n",
    "                        'ID-unique': ID_CN_test\n",
    "                    })\n",
    "\n",
    "    results_labels_df_CN_test = pd.concat([results_labels_df_CN_test, temp_CN_df_test], ignore_index=True)\n",
    "    results_per_fold_CN_test.append(temp_CN_df_test.copy())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Lista de métricas\n",
    "#metrics = ['mae', 'mse', 'rmse', 'r2']\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "#results = {'train': {m: [] for m in metrics}, \n",
    "#           #'val': {m: [] for m in metrics}, \n",
    "#           'test': {m: [] for m in metrics}}\n",
    "\n",
    "metrics = ['mae', 'mse', 'rmse', 'r2']\n",
    "results = {'train': {m: [] for m in metrics}, \n",
    "        'val': {m: [] for m in metrics}, \n",
    "        'test': {m: [] for m in metrics}}\n",
    "\n",
    "# Función para calcular las métricas\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2}\n",
    "\n",
    "# Recorrer los 10 folds\n",
    "for fold_idx in range(10):\n",
    "    fold_data_CN_train = results_per_fold_CN_train[0][fold_idx]\n",
    "    fold_data_CN_val = results_per_fold_CN_val[0][fold_idx]\n",
    "    fold_data_CN_test = results_per_fold_CN_test[fold_idx]\n",
    "\n",
    "    # Obtener los valores de y_labels e y_pred_corrected\n",
    "    y_true_1 = fold_data_CN_train['y_labels']\n",
    "    y_pred_1 = fold_data_CN_train['y_pred']\n",
    "    y_true_2 = fold_data_CN_val['y_labels']\n",
    "    y_pred_2 = fold_data_CN_val['y_pred']\n",
    "    y_true_3 = fold_data_CN_test['y_labels']\n",
    "    y_pred_3 = fold_data_CN_test['y_pred']\n",
    "    \n",
    "    # Calcular métricas para el fold actual\n",
    "    fold_metrics_1 = calculate_metrics(y_true_1, y_pred_1)\n",
    "    fold_metrics_2 = calculate_metrics(y_true_2, y_pred_2)\n",
    "    fold_metrics_3 = calculate_metrics(y_true_3, y_pred_3)\n",
    "\n",
    "    # Guardar los resultados en el diccionario\n",
    "    for metric in metrics:\n",
    "        results['train'][metric].append(fold_metrics_1[metric])\n",
    "        results['val'][metric].append(fold_metrics_2[metric]) \n",
    "        results['test'][metric].append(fold_metrics_3[metric]) \n",
    "\n",
    "# Imprimir resultados\n",
    "#for metric in metrics:\n",
    "#    print(f\"{metric}: {results['train'][metric]}\")\n",
    "\n",
    "labels = ['train', 'val','test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_metricas_evaluacion(results, labels=labels, name_set='Cross Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = results['val']['mae']\n",
    "min_mae_index = mae_list.index(min(mae_list))\n",
    "\n",
    "y_labels_=results_per_fold_CN_test[min_mae_index]['y_labels']\n",
    "y_pred_= results_per_fold_CN_test[min_mae_index]['y_pred_corrected']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_list = results['val']['mae']\n",
    "min_mae_index = mae_list.index(min(mae_list))\n",
    "\n",
    "y_labels_=results_per_fold_CN_test[min_mae_index]['y_labels']\n",
    "y_pred_= results_per_fold_CN_test[min_mae_index]['y_pred_corrected']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_regresion(y=y_pred_,x= y_labels_, label_='Test Data',x_ticks_step=25,y_ticks_step=25,x_min_limit=0,y_min_limit=0,x_max_limit=100,y_max_limit=100,color='Black', title='XGBoost',line_ideal=False,confidence_interval=True,  alpha=0.7,xlabel='Chronological Age',ylabel='Brain Age',color_confidence_interval='blue',alpha_confidence_interval=0.4,color_line_fit='red', details=True, font='Times New Roman', weight='normal', x_size=3,y_size=3, legend=False, fontsize=13, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_regresion(y=y_pred_,x= y_labels_, label_='Test Data',x_ticks_step=25,y_ticks_step=25,x_min_limit=0,y_min_limit=0,x_max_limit=100,y_max_limit=100,color='darkorange', title='XGBoost',line_ideal=False,confidence_interval=True,  alpha=0.5,xlabel='Chronological Age',ylabel='Brain Age',color_confidence_interval='gray',alpha_confidence_interval=0.7,color_line_fit=(0, 0, 0), details=False, font='Times New Roman', weight='normal', x_size=2,y_size=2.5, legend=False, fontsize=13, mode=3, legend_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_fold = results_per_fold_CN_train[0][min_mae_index]['ID-unique']\n",
    "df_train_fold = df_concatenado_CN[df_concatenado_CN['ID-unique'].isin(ID_fold)]\n",
    "\n",
    "X_train_kf_CN = df_train_fold.iloc[:, :-2]  # Features\n",
    "y_train_kf_CN = df_train_fold.iloc[:, -2]   # Labels (Age)\n",
    "id_train_kf_CN = df_train_fold.iloc[:, -1]\n",
    "\n",
    "mean_X_train_kf=results_model['mean_X_train_kf'][min_mae_index]\n",
    "std_X_train_kf=results_model['std_X_train_kf'][min_mae_index]\n",
    "\n",
    "best_model = results_model['model'][min_mae_index]\n",
    "\n",
    "X_train_kf_CN_scaled= (X_train_kf_CN - mean_X_train_kf) / std_X_train_kf\n",
    "X_test_CN_scaled = (X_CN_test - mean_X_train_kf) / std_X_train_kf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "model_= best_model\n",
    "explainer = shap.Explainer(model_, X_train_kf_CN_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test_CN_scaled)\n",
    "shap_sum = np.abs(shap_values).sum(axis=0)\n",
    "shap_summary = {feature: shap_sum[i] for i, feature in enumerate(X_test_CN_scaled.columns)}\n",
    "shap_summary_sorted = sorted(shap_summary.items(), key=lambda x: x[1], reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_feature_importance(shap_values=shap_values,X_test=X_test_CN_scaled,y_test=y_CN_test, font= \"Times New Roman\", fontsize=24, xlabel1='Shap Values', xlabel2='Sum of SHAP Values',ylabel='Features', ylabel1='Features Values', ylabel2='Age Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_por_region_sorted, resultado_normalizado_sorted=model.shap_region(shap_summary_sorted=shap_summary_sorted, num_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_normalized_values(resultado_normalizado_sorted, color='darkorange', name_set='XGBoost',x_size=3,y_size=3,font='Times New Roman', fontsize=12, xlabel='Values', ylabel='Regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f'{path}cerebritos/'\n",
    "\n",
    "Plotters.plot_brain_regions(resultado_normalizado_sorted, base_path, color='darkorange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taining Iteration Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_CN_train,results_labels_df_CN_test, results_labels_list, results_model, results_per_fold_CN_train,results_per_fold_CN_test, results_per_fold_pat= model.trainer(df_concatenado_CN=df_concatenado_CN, n_splits=10, n_iterations=20, params_=best_params_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "results_training = [results_labels_df_CN_train, results_labels_df_CN_test, results_labels_list, \n",
    "           results_model, results_per_fold_CN_train, results_per_fold_CN_test, results_per_fold_pat]\n",
    "\n",
    "with open('results_model/resultados_modelo.pkl', 'wb') as f:\n",
    "    pickle.dump(results_training, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_model/resultados_modelo.pkl', 'rb') as f:\n",
    "    loaded_results = pickle.load(f)\n",
    "\n",
    "# Acceder a los objetos\n",
    "results_labels_df_CN_train, results_labels_df_CN_test, results_labels_list, results_model, results_per_fold_CN_train, results_per_fold_CN_test, results_per_fold_pat = loaded_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels_df_total = [results_labels_df_CN_test]\n",
    "results_avg_list = model.avg_list(results_labels_df_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_avg_list_CN = results_avg_list[0]\n",
    "df_CN_seleccion = df_CN_filtrado[['ID-unique', 'Country_ID', 'Age', 'Sex', 'Educ', 'MMSE', 'HDI', 'GINI', 'ODQ']]\n",
    "df_CN_combined = results_avg_list_CN.merge(df_CN_seleccion, on='ID-unique', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CN_combined.to_excel('results/df_CN_combined.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_avg_list[0].to_excel('results/results_avg_list.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_regresion(y=results_avg_list[0]['y_pred_corrected'],x= results_avg_list[0]['y_labels'], label_='Test Data',x_ticks_step=25,y_ticks_step=25,x_min_limit=0,y_min_limit=0,x_max_limit=100,y_max_limit=100,color='Black', title='Lasso',line_ideal=False,confidence_interval=True,  alpha=0.7,xlabel='Chronological Age',ylabel='Brain Age',color_confidence_interval='blue',alpha_confidence_interval=0.4,color_line_fit='red', details=True, font='Times New Roman', weight='normal', x_size=3,y_size=3, legend=False, fontsize=13, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_regresion(y=results_avg_list[0]['y_pred_corrected'],x= results_avg_list[0]['y_labels'], label_='Test Data',x_ticks_step=25,y_ticks_step=25,x_min_limit=0,y_min_limit=0,x_max_limit=100,y_max_limit=100,color='darkorange', title='Lasso',line_ideal=False,confidence_interval=True,  alpha=0.5,xlabel='Chronological Age',ylabel='Brain Age',color_confidence_interval='gray',alpha_confidence_interval=0.7,color_line_fit=(0, 0, 0), details=False, font='Times New Roman', weight='normal', x_size=2,y_size=2.5, legend=False, fontsize=13, mode=3, legend_metrics=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "shap_values_dict = {id_unique: [] for id_unique in df_concatenado_CN['ID-unique'].unique()}\n",
    "\n",
    "for i in range(20):\n",
    "    for j in range(10):\n",
    "\n",
    "        ID_train_fold = results_per_fold_CN_train[i][j]['ID-unique']\n",
    "        df_train_fold = df_concatenado_CN[df_concatenado_CN['ID-unique'].isin(ID_train_fold)]\n",
    "        X_train_kf_CN = df_train_fold.iloc[:, :-2]  # Features\n",
    "        y_train_kf_CN = df_train_fold.iloc[:, -2]   # Labels (Age)\n",
    "        id_train_kf_CN = df_train_fold.iloc[:, -1]\n",
    "\n",
    "        ID_test_fold = results_per_fold_CN_test[i][j]['ID-unique']\n",
    "        df_test_fold = df_concatenado_CN[df_concatenado_CN['ID-unique'].isin(ID_test_fold)]\n",
    "        X_test_kf_CN = df_test_fold.iloc[:, :-2]  # Features\n",
    "        y_test_kf_CN = df_test_fold.iloc[:, -2]   # Labels (Age)\n",
    "        id_test_kf_CN = df_test_fold.iloc[:, -1]\n",
    "\n",
    "        mean_X_train_kf = results_model['mean_X_train_kf'][j + 10 * i]\n",
    "        std_X_train_kf = results_model['std_X_train_kf'][j + 10 * i]\n",
    "\n",
    "        X_train_kf_CN_scaled = (X_train_kf_CN - mean_X_train_kf) / std_X_train_kf\n",
    "        X_test_kf_CN_scaled = (X_test_kf_CN - mean_X_train_kf) / std_X_train_kf\n",
    "\n",
    "        model_ = results_model['model'][j + 10 * i]\n",
    "\n",
    "        # Calcular los valores SHAP\n",
    "        explainer = shap.Explainer(model_, X_train_kf_CN_scaled)\n",
    "        shap_values = explainer.shap_values(X_test_kf_CN_scaled)\n",
    "\n",
    "        # Almacenar los valores SHAP en el diccionario\n",
    "        for idx, id_unique in enumerate(df_test_fold['ID-unique']):\n",
    "            shap_values_dict[id_unique].append(shap_values[idx])\n",
    "\n",
    "# Promediar los valores SHAP para cada ID-unique\n",
    "shap_values_avg_dict = {id_unique: np.mean(values, axis=0) for id_unique, values in shap_values_dict.items()}\n",
    "\n",
    "shap_values_avg_matrix = []\n",
    "\n",
    "feature_names = X_test_kf_CN_scaled.columns.tolist()\n",
    "\n",
    "for id_unique in df_concatenado_CN['ID-unique'].unique():\n",
    "    if id_unique in shap_values_avg_dict:\n",
    "        shap_values_avg_matrix.append(shap_values_avg_dict[id_unique])\n",
    "\n",
    "shap_values_avg_array = np.array(shap_values_avg_matrix)\n",
    "\n",
    "shap_values_df = pd.DataFrame(shap_values_avg_array, columns=feature_names)\n",
    "shap_values_df['ID-unique'] = df_concatenado_CN['ID-unique'].unique()\n",
    "\n",
    "shap_values_df.set_index('ID-unique', inplace=True)\n",
    "\n",
    "shap_sum = np.abs(shap_values_avg_array).sum(axis=0)\n",
    "# Crear un diccionario para almacenar la suma de SHAP por característica\n",
    "shap_summary = {feature: shap_sum[i] for i, feature in enumerate(X_CN.columns)}\n",
    "\n",
    "# Ordenar las características por su suma de SHAP\n",
    "shap_summary_sorted = sorted(shap_summary.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Imprimir el listado de importancia de características\n",
    "print(\"Importancia de características basada en suma de valores SHAP:\")\n",
    "for feature, shap_sum in shap_summary_sorted:\n",
    "    print(f\"{feature}: {shap_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_model/shap_summary_sorted.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_summary_sorted, f)\n",
    "\n",
    "with open('results_model/shap_values_avg_array.pkl', 'wb') as f:\n",
    "    pickle.dump(shap_values_avg_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_model/shap_summary_sorted.pkl', 'rb') as f:\n",
    "    shap_summary_sorted = pickle.load(f)\n",
    "\n",
    "with open('results_model/shap_values_avg_array.pkl', 'rb') as f:\n",
    "    shap_values_avg_array = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_feature_importance(shap_values=shap_values_avg_array,X_test=X_CN_scaled,y_test=y_CN, font= \"Times New Roman\", fontsize=24, xlabel1='Shap Values', xlabel2='Sum of SHAP Values',ylabel='Features', ylabel1='Features Values', ylabel2='Age Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_por_region_sorted, resultado_normalizado_sorted=model.shap_region(shap_summary_sorted=shap_summary_sorted, num_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotters.plot_normalized_values(resultado_normalizado_sorted, color='darkorange', name_set='XGBoost',x_size=3,y_size=3,font='Times New Roman', fontsize=12, xlabel='Values', ylabel='Regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f'{path}cerebritos/'\n",
    "\n",
    "Plotters.plot_brain_regions(resultado_normalizado_sorted, base_path, color='darkorange')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_age_env (C:\\python_env\\brain_age_env)",
   "language": "python",
   "name": "brain_age_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
